{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88600c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def first_order_features(gray_img):\n",
    "    flat = gray_img.flatten()\n",
    "    hist = np.bincount(flat, minlength=256) / len(flat)\n",
    "    indices = np.arange(256)\n",
    "    mean = np.sum(indices * hist)\n",
    "    variance = np.sum((indices - mean)**2 * hist)\n",
    "    if variance == 0:\n",
    "        skewness = 0\n",
    "        kurtosis = 0\n",
    "    else:\n",
    "        skewness = np.sum(((indices - mean) / np.sqrt(variance))**3 * hist)\n",
    "        kurtosis = np.sum(((indices - mean) / np.sqrt(variance))**4 * hist) - 3\n",
    "    energy = np.sum(hist**2)\n",
    "    entropy = -np.sum(hist * np.log2(hist + (hist == 0)))\n",
    "    return [mean, variance, skewness, kurtosis, energy, entropy]\n",
    "\n",
    "def calculate_glcm(gray_img, dx, dy, levels):\n",
    "    glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "    height, width = gray_img.shape\n",
    "    start_i = max(0, -dy)\n",
    "    end_i = height - max(0, dy)\n",
    "    start_j = max(0, -dx)\n",
    "    end_j = width - max(0, dx)\n",
    "    for i in range(start_i, end_i):\n",
    "        for j in range(start_j, end_j):\n",
    "            i2 = i + dy\n",
    "            j2 = j + dx\n",
    "            val1 = gray_img[i, j]\n",
    "            val2 = gray_img[i2, j2]\n",
    "            glcm[val1, val2] += 1\n",
    "    glcm += glcm.T\n",
    "    total = glcm.sum()\n",
    "    if total > 0:\n",
    "        glcm /= total\n",
    "    return glcm\n",
    "\n",
    "def glcm_features(glcm_avg, levels):\n",
    "    p = glcm_avg\n",
    "    i, j = np.ogrid[0:levels, 0:levels]\n",
    "    p_x = np.sum(p, axis=1)\n",
    "    p_y = np.sum(p, axis=0)\n",
    "    mu_x = np.sum(i[:, 0] * p_x)\n",
    "    mu_y = np.sum(j[0, :] * p_y)\n",
    "    sigma_x_sq = np.sum((i[:, 0] - mu_x)**2 * p_x)\n",
    "    sigma_y_sq = np.sum((j[0, :] - mu_y)**2 * p_y)\n",
    "    sigma_x = np.sqrt(sigma_x_sq)\n",
    "    sigma_y = np.sqrt(sigma_y_sq)\n",
    "\n",
    "    # ASM\n",
    "    asm = np.sum(p ** 2)\n",
    "\n",
    "    # Contrast\n",
    "    contrast = np.sum(p * (i - j)**2)\n",
    "\n",
    "    # Correlation\n",
    "    if sigma_x * sigma_y == 0:\n",
    "        correlation = 1\n",
    "    else:\n",
    "        correlation = np.sum(p * (i - mu_x) * (j - mu_y)) / (sigma_x * sigma_y)\n",
    "\n",
    "    # Variance\n",
    "    variance = np.sum(p * (i - mu_x)**2)\n",
    "\n",
    "    # IDM / Homogeneity\n",
    "    idm = np.sum(p / (1 + (i - j)**2))\n",
    "\n",
    "    # p_xplusy\n",
    "    max_sum = 2 * (levels - 1)\n",
    "    p_xplusy = np.zeros(max_sum + 1)\n",
    "    for ii in range(levels):\n",
    "        for jj in range(levels):\n",
    "            p_xplusy[ii + jj] += p[ii, jj]\n",
    "\n",
    "    # Sum Average\n",
    "    sum_avg = np.sum(np.arange(max_sum + 1) * p_xplusy)\n",
    "\n",
    "    # Sum Variance\n",
    "    sum_var = np.sum((np.arange(max_sum + 1) - sum_avg)**2 * p_xplusy)\n",
    "\n",
    "    # Sum Entropy\n",
    "    sum_ent = -np.sum(p_xplusy * np.log2(p_xplusy + (p_xplusy == 0)))\n",
    "\n",
    "    # Entropy\n",
    "    ent = -np.sum(p * np.log2(p + (p == 0)))\n",
    "\n",
    "    # p_xminusy\n",
    "    max_diff = levels - 1\n",
    "    p_xminusy = np.zeros(max_diff + 1)\n",
    "    for ii in range(levels):\n",
    "        for jj in range(levels):\n",
    "            p_xminusy[abs(ii - jj)] += p[ii, jj]\n",
    "\n",
    "    # Difference Variance\n",
    "    diff_mean = np.sum(np.arange(max_diff + 1) * p_xminusy)\n",
    "    diff_var = np.sum(np.arange(max_diff + 1)**2 * p_xminusy) - diff_mean**2\n",
    "\n",
    "    # Difference Entropy\n",
    "    diff_ent = -np.sum(p_xminusy * np.log2(p_xminusy + (p_xminusy == 0)))\n",
    "\n",
    "    # IMC1, IMC2\n",
    "    HX = -np.sum(p_x * np.log2(p_x + (p_x == 0)))\n",
    "    HY = -np.sum(p_y * np.log2(p_y + (p_y == 0)))\n",
    "    HXY = ent\n",
    "    HXY1 = -np.sum(p * np.log2(p_x[:, np.newaxis] * p_y[np.newaxis, :] + 1e-10))\n",
    "    HXY2 = -np.sum(p_x[:, np.newaxis] * p_y[np.newaxis, :] * np.log2(p_x[:, np.newaxis] * p_y[np.newaxis, :] + 1e-10))\n",
    "    if max(HX, HY) == 0:\n",
    "        imc1 = 0\n",
    "    else:\n",
    "        imc1 = (HXY - HXY1) / max(HX, HY)\n",
    "    imc2 = np.sqrt(max(0, 1 - np.exp(-2 * (HXY2 - HXY))))\n",
    "\n",
    "    # MCC\n",
    "    Q = np.zeros((levels, levels))\n",
    "    for ii in range(levels):\n",
    "        if p_x[ii] == 0:\n",
    "            continue\n",
    "        for jj in range(levels):\n",
    "            Q[ii, jj] = np.dot(p[ii, :], p[jj, :] / (p_x + 1e-10)) / p_x[ii]\n",
    "    eigs = np.linalg.eigvals(Q)\n",
    "    sorted_eigs = np.sort(np.real(eigs))[::-1]\n",
    "    mcc = np.sqrt(sorted_eigs[1]) if len(sorted_eigs) > 1 and sorted_eigs[1] >= 0 else 0\n",
    "\n",
    "    return [asm, contrast, correlation, variance, idm, sum_avg, sum_var, sum_ent, ent, diff_var, diff_ent, imc1, imc2, mcc]\n",
    "\n",
    "def main(image_path):\n",
    "    # Load image\n",
    "    img = plt.imread(\"C:/Users/User/Pictures/colosnoscopy.png\")\n",
    "    if len(img.shape) == 3:\n",
    "        # Convert to grayscale using luminance\n",
    "        gray = np.dot(img[..., :3], [0.299, 0.587, 0.114])\n",
    "    else:\n",
    "        gray = img\n",
    "    if gray.dtype == np.float32 or gray.dtype == np.float64:\n",
    "        gray = (gray * 255).astype(np.uint8)\n",
    "    else:\n",
    "        gray = gray.astype(np.uint8)\n",
    "\n",
    "    # First-order features (on original grayscale)\n",
    "    fo_values = first_order_features(gray)\n",
    "    fo_names = ['Mean', 'Variance', 'Skewness', 'Kurtosis', 'Energy', 'Entropy']\n",
    "\n",
    "    # Quantize for GLCM\n",
    "    levels = 32\n",
    "    gray_quant = (gray // (256 // levels)).astype(int)\n",
    "\n",
    "    # Compute GLCMs\n",
    "    directions = [(1, 0), (1, 1), (0, 1), (-1, 1)]\n",
    "    glcms = [calculate_glcm(gray_quant, dx, dy, levels) for dx, dy in directions]\n",
    "    glcm_avg = np.mean(glcms, axis=0)\n",
    "\n",
    "    # GLCM features\n",
    "    glcm_values = glcm_features(glcm_avg, levels)\n",
    "    glcm_names = ['ASM', 'Contrast', 'Correlation', 'Variance', 'Homogeneity', 'Sum Average', 'Sum Variance', 'Sum Entropy', 'Entropy', 'Difference Variance', 'Difference Entropy', 'IMC1', 'IMC2', 'MCC']\n",
    "\n",
    "    # Print features\n",
    "    print(\"First-Order Texture Features:\")\n",
    "    for name, val in zip(fo_names, fo_values):\n",
    "        print(f\"{name}: {val:.4f}\")\n",
    "\n",
    "    print(\"\\nGLCM Texture Features (Averaged over directions):\")\n",
    "    for name, val in zip(glcm_names, glcm_values):\n",
    "        print(f\"{name}: {val:.4f}\")\n",
    "\n",
    "    # Plots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axs[0].imshow(gray, cmap='gray')\n",
    "    axs[0].set_title('Grayscale Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    flat = gray.flatten()\n",
    "    axs[1].hist(flat, bins=256, density=True, color='blue')\n",
    "    axs[1].set_title('Intensity Histogram')\n",
    "\n",
    "    axs[2].imshow(glcm_avg, cmap='jet')\n",
    "    axs[2].set_title('Average GLCM')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) > 1:\n",
    "        main(sys.argv[1])\n",
    "    else:\n",
    "        print(\"Please provide the image path as a command-line argument.\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Your 20 feature values (example - replace with your real values)\n",
    "features = [\n",
    "    'Mean', 'Variance', 'Skewness', 'Kurtosis', 'Energy', 'Entropy',\n",
    "    'ASM', 'Contrast', 'Correlation', 'Variance(GLCM)', 'Homogeneity',\n",
    "    'Sum Avg', 'Sum Var', 'Sum Ent', 'Entropy(GLCM)', 'Diff Var',\n",
    "    'Diff Ent', 'IMC1', 'IMC2', 'MCC'\n",
    "]\n",
    "\n",
    "values = [124.7, 1842.3, 0.12, 2.85, 0.0042, 6.81,    # first order\n",
    "          0.021, 18.4, 0.87, 1650.2, 0.34, 110.5, 4200, 4.92, 5.11, 12.8, 2.41, 0.19, 0.82, 0.73]  # glcm example\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.bar(features, values, color='teal', edgecolor='black')\n",
    "plt.xticks(rotation=60, ha='right', fontsize=10)\n",
    "plt.ylabel('Value')\n",
    "plt.title('Texture Features - Colonoscopy Image')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33e6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 9))\n",
    "y_pos = np.arange(len(features))\n",
    "\n",
    "plt.barh(y_pos, values, color='cornflowerblue', edgecolor='navy')\n",
    "plt.yticks(y_pos, features)\n",
    "plt.xlabel('Value')\n",
    "plt.title('Texture Features Comparison')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f49994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "angles = [n / float(len(features)) * 2 * pi for n in range(len(features))]\n",
    "angles += angles[:1]  # close the polygon\n",
    "\n",
    "values_plot = values + values[:1]  # close\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8), subplot_kw=dict(polar=True))\n",
    "\n",
    "ax.plot(angles, values_plot, linewidth=2, linestyle='solid', label='Image 1')\n",
    "ax.fill(angles, values_plot, alpha=0.25)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(features, fontsize=9)\n",
    "ax.set_title('Texture Feature Profile (Radar Chart)', pad=20, fontsize=13)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2670be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "\n",
    "def plot_radar_chart(features, values, title=\"Colonoscopy Texture Profile\"):\n",
    "    # Number of variables/categories\n",
    "    categories = features\n",
    "    N = len(categories)\n",
    "    \n",
    "    # What will be our angles for each axis\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]  # complete the loop\n",
    "    \n",
    "    # Initialise the spider plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    \n",
    "    # Draw one axe per variable + add labels\n",
    "    plt.xticks(angles[:-1], categories, size=11)\n",
    "    \n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks(color='grey', size=9)\n",
    "    plt.ylim(0, max(values)*1.15)  # adjust upper limit if needed\n",
    "    \n",
    "    # Plot data\n",
    "    values_plot = values + values[:1]  # complete the polygon\n",
    "    ax.plot(angles, values_plot, linewidth=2, linestyle='solid', label='Features')\n",
    "    ax.fill(angles, values_plot, 'b', alpha=0.15)\n",
    "    \n",
    "    # Add title and show\n",
    "    plt.title(title, size=14, color='black', y=1.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Example usage with your features\n",
    "\n",
    "features = [\n",
    "    'Mean', 'Variance', 'Skewness', 'Kurtosis', 'Energy', 'Entropy',\n",
    "    'ASM', 'Contrast', 'Correlation', 'GLCM Var', 'Homogeneity',\n",
    "    'Sum Avg', 'Sum Var', 'Sum Ent', 'GLCM Ent', 'Diff Var',\n",
    "    'Diff Ent', 'IMC1', 'IMC2', 'MCC'\n",
    "]\n",
    "\n",
    "# Replace with your actual extracted values\n",
    "values = [125.3, 1840, 0.18, 3.1, 0.0041, 6.92,\n",
    "          0.022, 19.8, 0.84, 1620, 0.36,\n",
    "          112.4, 4150, 4.88, 5.21, 13.4,\n",
    "          2.52, 0.21, 0.79, 0.71]\n",
    "\n",
    "plot_radar_chart(features, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def plot_single_row_heatmap(features, values, title=\"Texture Features Heatmap\"):\n",
    "    # Create DataFrame with one row\n",
    "    df = pd.DataFrame(\n",
    "        [values],\n",
    "        columns=features,\n",
    "        index=[\"Image\"]\n",
    "    )\n",
    "    \n",
    "    # Figure setup\n",
    "    plt.figure(figsize=(14, 3))\n",
    "    \n",
    "    # Heatmap with annotations\n",
    "    ax = sns.heatmap(\n",
    "        df,\n",
    "        annot=True,                # show numbers\n",
    "        fmt=\".2f\",                 # 2 decimal places\n",
    "        cmap=\"YlGnBu\",             # nice color scale\n",
    "        linewidths=1,\n",
    "        cbar=False,                # usually no need for colorbar in single row\n",
    "        annot_kws={\"size\": 11}\n",
    "    )\n",
    "    \n",
    "    # Improve readability\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=60, ha='right', fontsize=10)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=11)\n",
    "    ax.set_title(title, fontsize=14, pad=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Example usage\n",
    "\n",
    "features = [\n",
    "    'Mean', 'Variance', 'Skewness', 'Kurtosis', 'Energy', 'Entropy',\n",
    "    'ASM', 'Contrast', 'Correlation', 'GLCM Var', 'Homogeneity',\n",
    "    'Sum Avg', 'Sum Var', 'Sum Ent', 'GLCM Ent', 'Diff Var',\n",
    "    'Diff Ent', 'IMC1', 'IMC2', 'MCC'\n",
    "]\n",
    "\n",
    "values = [125.3, 1840, 0.18, 3.1, 0.0041, 6.92,\n",
    "          0.022, 19.8, 0.84, 1620, 0.36,\n",
    "          112.4, 4150, 4.88, 5.21, 13.4,\n",
    "          2.52, 0.21, 0.79, 0.71]\n",
    "\n",
    "plot_single_row_heatmap(features, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34287da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def ensure_dir(path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def first_order_features(gray_img):\n",
    "    flat = gray_img.flatten()\n",
    "    hist = np.bincount(flat, minlength=256) / len(flat)\n",
    "    indices = np.arange(256)\n",
    "    mean = np.sum(indices * hist)\n",
    "    variance = np.sum((indices - mean)**2 * hist)\n",
    "    if variance == 0:\n",
    "        skewness = 0\n",
    "        kurtosis = 0\n",
    "    else:\n",
    "        skewness = np.sum(((indices - mean) / np.sqrt(variance))**3 * hist)\n",
    "        kurtosis = np.sum(((indices - mean) / np.sqrt(variance))**4 * hist) - 3\n",
    "    energy = np.sum(hist**2)\n",
    "    entropy = -np.sum(hist * np.log2(hist + (hist == 0)))\n",
    "    return [mean, variance, skewness, kurtosis, energy, entropy]\n",
    "\n",
    "def calculate_glcm(gray_img, dx, dy, levels):\n",
    "    glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "    height, width = gray_img.shape\n",
    "    start_i = max(0, -dy)\n",
    "    end_i = height - max(0, dy)\n",
    "    start_j = max(0, -dx)\n",
    "    end_j = width - max(0, dx)\n",
    "    for i in range(start_i, end_i):\n",
    "        for j in range(start_j, end_j):\n",
    "            i2 = i + dy\n",
    "            j2 = j + dx\n",
    "            val1 = gray_img[i, j]\n",
    "            val2 = gray_img[i2, j2]\n",
    "            glcm[val1, val2] += 1\n",
    "    glcm += glcm.T\n",
    "    total = glcm.sum()\n",
    "    if total > 0:\n",
    "        glcm /= total\n",
    "    return glcm\n",
    "\n",
    "def glcm_features(glcm_avg, levels):\n",
    "    p = glcm_avg\n",
    "    i, j = np.ogrid[0:levels, 0:levels]\n",
    "    p_x = np.sum(p, axis=1)\n",
    "    p_y = np.sum(p, axis=0)\n",
    "    mu_x = np.sum(i[:, 0] * p_x)\n",
    "    mu_y = np.sum(j[0, :] * p_y)\n",
    "    sigma_x_sq = np.sum((i[:, 0] - mu_x)**2 * p_x)\n",
    "    sigma_y_sq = np.sum((j[0, :] - mu_y)**2 * p_y)\n",
    "    sigma_x = np.sqrt(sigma_x_sq)\n",
    "    sigma_y = np.sqrt(sigma_y_sq)\n",
    "\n",
    "    # ASM\n",
    "    asm = np.sum(p ** 2)\n",
    "\n",
    "    # Contrast\n",
    "    contrast = np.sum(p * (i - j)**2)\n",
    "\n",
    "    # Correlation\n",
    "    if sigma_x * sigma_y == 0:\n",
    "        correlation = 1\n",
    "    else:\n",
    "        correlation = np.sum(p * (i - mu_x) * (j - mu_y)) / (sigma_x * sigma_y)\n",
    "\n",
    "    # Variance\n",
    "    variance = np.sum(p * (i - mu_x)**2)\n",
    "\n",
    "    # IDM / Homogeneity\n",
    "    idm = np.sum(p / (1 + (i - j)**2))\n",
    "\n",
    "    # p_xplusy\n",
    "    max_sum = 2 * (levels - 1)\n",
    "    p_xplusy = np.zeros(max_sum + 1)\n",
    "    for ii in range(levels):\n",
    "        for jj in range(levels):\n",
    "            p_xplusy[ii + jj] += p[ii, jj]\n",
    "\n",
    "    # Sum Average\n",
    "    sum_avg = np.sum(np.arange(max_sum + 1) * p_xplusy)\n",
    "\n",
    "    # Sum Variance\n",
    "    sum_var = np.sum((np.arange(max_sum + 1) - sum_avg)**2 * p_xplusy)\n",
    "\n",
    "    # Sum Entropy\n",
    "    sum_ent = -np.sum(p_xplusy * np.log2(p_xplusy + (p_xplusy == 0)))\n",
    "\n",
    "    # Entropy\n",
    "    ent = -np.sum(p * np.log2(p + (p == 0)))\n",
    "\n",
    "    # p_xminusy\n",
    "    max_diff = levels - 1\n",
    "    p_xminusy = np.zeros(max_diff + 1)\n",
    "    for ii in range(levels):\n",
    "        for jj in range(levels):\n",
    "            p_xminusy[abs(ii - jj)] += p[ii, jj]\n",
    "\n",
    "    # Difference Variance\n",
    "    diff_mean = np.sum(np.arange(max_diff + 1) * p_xminusy)\n",
    "    diff_var = np.sum(np.arange(max_diff + 1)**2 * p_xminusy) - diff_mean**2\n",
    "\n",
    "    # Difference Entropy\n",
    "    diff_ent = -np.sum(p_xminusy * np.log2(p_xminusy + (p_xminusy == 0)))\n",
    "\n",
    "    # IMC1, IMC2\n",
    "    HX = -np.sum(p_x * np.log2(p_x + (p_x == 0)))\n",
    "    HY = -np.sum(p_y * np.log2(p_y + (p_y == 0)))\n",
    "    HXY = ent\n",
    "    HXY1 = -np.sum(p * np.log2(p_x[:, np.newaxis] * p_y[np.newaxis, :] + 1e-10))\n",
    "    HXY2 = -np.sum(p_x[:, np.newaxis] * p_y[np.newaxis, :] * np.log2(p_x[:, np.newaxis] * p_y[np.newaxis, :] + 1e-10))\n",
    "    if max(HX, HY) == 0:\n",
    "        imc1 = 0\n",
    "    else:\n",
    "        imc1 = (HXY - HXY1) / max(HX, HY)\n",
    "    imc2 = np.sqrt(max(0, 1 - np.exp(-2 * (HXY2 - HXY))))\n",
    "\n",
    "    # MCC\n",
    "    Q = np.zeros((levels, levels))\n",
    "    for ii in range(levels):\n",
    "        if p_x[ii] == 0:\n",
    "            continue\n",
    "        for jj in range(levels):\n",
    "            Q[ii, jj] = np.dot(p[ii, :], p[jj, :] / (p_x + 1e-10)) / p_x[ii]\n",
    "    eigs = np.linalg.eigvals(Q)\n",
    "    sorted_eigs = np.sort(np.real(eigs))[::-1]\n",
    "    mcc = np.sqrt(sorted_eigs[1]) if len(sorted_eigs) > 1 and sorted_eigs[1] >= 0 else 0\n",
    "\n",
    "    return [asm, contrast, correlation, variance, idm, sum_avg, sum_var, sum_ent, ent, diff_var, diff_ent, imc1, imc2, mcc]\n",
    "\n",
    "\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# NEW: Local/patch-based texture FEATURE MAPS (visual representation of numbers)\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def _quantize_to_levels(gray_u8, levels):\n",
    "    \"\"\"Map uint8 [0..255] -> uint8 [0..levels-1].\"\"\"\n",
    "    if levels <= 1:\n",
    "        return np.zeros_like(gray_u8, dtype=np.uint8)\n",
    "    # Use floor mapping for stable bins\n",
    "    q = (gray_u8.astype(np.int32) * levels) // 256\n",
    "    q = np.clip(q, 0, levels - 1).astype(np.uint8)\n",
    "    return q\n",
    "\n",
    "def _average_glcm_over_offsets(patch_q, offsets, levels):\n",
    "    \"\"\"Average symmetric GLCM over a list of (dx,dy) offsets.\"\"\"\n",
    "    glcms = []\n",
    "    for dx, dy in offsets:\n",
    "        glcms.append(calculate_glcm(patch_q, dx=dx, dy=dy, levels=levels))\n",
    "    glcm_avg = np.mean(glcms, axis=0) if len(glcms) else np.zeros((levels, levels), dtype=np.float64)\n",
    "    # Re-normalize\n",
    "    s = glcm_avg.sum()\n",
    "    if s > 0:\n",
    "        glcm_avg = glcm_avg / s\n",
    "    return glcm_avg\n",
    "\n",
    "def texture_feature_maps(gray_img_u8, win=32, step=8, levels=32, offsets=None, features_to_map=None):\n",
    "    \"\"\"\n",
    "    Compute local texture feature maps by sliding-window GLCM analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gray_img_u8 : (H,W) uint8\n",
    "    win, step   : window size and stride in pixels\n",
    "    levels      : GLCM quantization levels (e.g., 16/32/64). Lower = faster.\n",
    "    offsets     : list of (dx,dy). Default: 0°,45°,90°,135° at distance=1.\n",
    "    features_to_map : list of feature names to map.\n",
    "        Supported (GLCM): 'ASM','Contrast','Correlation','GLCM Variance','Homogeneity',\n",
    "                          'Sum Average','Sum Variance','Sum Entropy','GLCM Entropy',\n",
    "                          'Difference Variance','Difference Entropy','IMC1','IMC2','MCC'\n",
    "        Supported (First-order): 'Mean','Variance','Skewness','Kurtosis','Energy','Entropy'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fmap_dict : dict[str, 2D float array]   # patch-grid maps\n",
    "    meta      : dict with ys,xs,covered_w,covered_h\n",
    "    \"\"\"\n",
    "    if offsets is None:\n",
    "        offsets = [(1, 0), (1, -1), (0, -1), (-1, -1)]\n",
    "    if features_to_map is None:\n",
    "        features_to_map = ['Contrast', 'Homogeneity', 'GLCM Entropy', 'Entropy']\n",
    "\n",
    "    H, W = gray_img_u8.shape\n",
    "    ys = list(range(0, H - win + 1, step))\n",
    "    xs = list(range(0, W - win + 1, step))\n",
    "    if len(ys) == 0 or len(xs) == 0:\n",
    "        return {}, {\"ys\": ys, \"xs\": xs, \"covered_w\": 0, \"covered_h\": 0}\n",
    "\n",
    "    covered_w = xs[-1] + win\n",
    "    covered_h = ys[-1] + win\n",
    "\n",
    "    # Prepare outputs\n",
    "    fmap_dict = {k: np.zeros((len(ys), len(xs)), dtype=np.float32) for k in features_to_map}\n",
    "\n",
    "    for iy, y in enumerate(ys):\n",
    "        for ix, x in enumerate(xs):\n",
    "            patch = gray_img_u8[y:y+win, x:x+win]\n",
    "\n",
    "            # First-order features on raw 0..255\n",
    "            fo = first_order_features(patch)\n",
    "            fo_names = ['Mean','Variance','Skewness','Kurtosis','Energy','Entropy']\n",
    "            fo_map = dict(zip(fo_names, fo))\n",
    "\n",
    "            # GLCM features on quantized patch\n",
    "            patch_q = _quantize_to_levels(patch, levels)\n",
    "            glcm_avg = _average_glcm_over_offsets(patch_q, offsets, levels)\n",
    "            gl = glcm_features(glcm_avg, levels)\n",
    "            gl_names = ['ASM','Contrast','Correlation','GLCM Variance','Homogeneity',\n",
    "                        'Sum Average','Sum Variance','Sum Entropy','GLCM Entropy',\n",
    "                        'Difference Variance','Difference Entropy','IMC1','IMC2','MCC']\n",
    "            gl_map = dict(zip(gl_names, gl))\n",
    "\n",
    "            for name in features_to_map:\n",
    "                if name in fo_map:\n",
    "                    fmap_dict[name][iy, ix] = fo_map[name]\n",
    "                elif name in gl_map:\n",
    "                    fmap_dict[name][iy, ix] = gl_map[name]\n",
    "                else:\n",
    "                    fmap_dict[name][iy, ix] = np.nan\n",
    "\n",
    "    meta = {\"ys\": ys, \"xs\": xs, \"covered_w\": covered_w, \"covered_h\": covered_h}\n",
    "    return fmap_dict, meta\n",
    "\n",
    "def _normalize_map(m):\n",
    "    m = np.asarray(m, dtype=np.float32)\n",
    "    finite = np.isfinite(m)\n",
    "    if not np.any(finite):\n",
    "        return np.zeros_like(m, dtype=np.float32)\n",
    "    mn = np.min(m[finite]); mx = np.max(m[finite])\n",
    "    if mx - mn < 1e-12:\n",
    "        return np.zeros_like(m, dtype=np.float32)\n",
    "    out = (m - mn) / (mx - mn)\n",
    "    out[~finite] = 0.0\n",
    "    return out\n",
    "\n",
    "def plot_feature_maps(gray_img_u8, fmap_dict, meta, image_title=\"\", overlay_alpha=0.45, save_dir=None, dpi=300):\n",
    "    \"\"\"\n",
    "    Visualize feature maps as (1) heatmap-only and (2) overlay on original image.\n",
    "    Saves PNGs if save_dir is provided.\n",
    "    \"\"\"\n",
    "    if not fmap_dict:\n",
    "        print(\"⚠️ Feature map skipped: window/step too large for image size.\")\n",
    "        return\n",
    "\n",
    "    gray = gray_img_u8.astype(np.float32) / 255.0\n",
    "    covered_w = meta[\"covered_w\"]; covered_h = meta[\"covered_h\"]\n",
    "\n",
    "    for feat_name, fmap in fmap_dict.items():\n",
    "        fmap_n = _normalize_map(fmap)\n",
    "\n",
    "        # Heatmap-only\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.imshow(fmap_n, cmap=\"jet\", interpolation=\"nearest\")\n",
    "        plt.title(f\"{image_title} | {feat_name} (normalized)\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        if save_dir:\n",
    "            ensure_dir(save_dir)\n",
    "            out1 = os.path.join(save_dir, f\"{image_title}_{feat_name}_heatmap.png\".replace(\" \", \"_\"))\n",
    "            plt.savefig(out1, dpi=dpi, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Overlay\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(gray, cmap=\"gray\")\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(gray, cmap=\"gray\")\n",
    "        plt.imshow(\n",
    "            fmap_n, cmap=\"jet\", alpha=overlay_alpha,\n",
    "            extent=[0, covered_w, covered_h, 0],\n",
    "            interpolation=\"nearest\"\n",
    "        )\n",
    "        plt.title(f\"{feat_name} overlay\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        if save_dir:\n",
    "            out2 = os.path.join(save_dir, f\"{image_title}_{feat_name}_overlay.png\".replace(\" \", \"_\"))\n",
    "            plt.savefig(out2, dpi=dpi, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "def analyze_image(image_path):\n",
    "    # Load image\n",
    "    img = plt.imread(\"C:/Users/User/Pictures/colosnoscopy.png\")\n",
    "    if len(img.shape) == 3:\n",
    "        # Convert to grayscale using luminance\n",
    "        gray = np.dot(img[..., :3], [0.299, 0.587, 0.114])\n",
    "    else:\n",
    "        gray = img\n",
    "    if gray.dtype == np.float32 or gray.dtype == np.float64:\n",
    "        gray = (gray * 255).astype(np.uint8)\n",
    "    else:\n",
    "        gray = gray.astype(np.uint8)\n",
    "\n",
    "    # First-order features\n",
    "    fo_values = first_order_features(gray)\n",
    "\n",
    "    # Quantize for GLCM\n",
    "    levels = 32\n",
    "    gray_quant = (gray // (256 // levels)).astype(int)\n",
    "\n",
    "    # Compute GLCMs\n",
    "    directions = [(1, 0), (1, 1), (0, 1), (-1, 1)]\n",
    "    glcms = [calculate_glcm(gray_quant, dx, dy, levels) for dx, dy in directions]\n",
    "    glcm_avg = np.mean(glcms, axis=0)\n",
    "\n",
    "    # GLCM features\n",
    "    glcm_values = glcm_features(glcm_avg, levels)\n",
    "\n",
    "    # Combine all features\n",
    "    all_values = fo_values + glcm_values\n",
    "\n",
    "    return gray, glcm_avg, all_values\n",
    "\n",
    "def main(image_paths):\n",
    "    if not image_paths:\n",
    "        print(\"Please provide image paths as command-line arguments.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    feature_names = [\n",
    "        'Mean', 'Variance', 'Skewness', 'Kurtosis', 'Energy', 'Entropy',\n",
    "        'ASM', 'Contrast', 'Correlation', 'GLCM Variance', 'Homogeneity',\n",
    "        'Sum Average', 'Sum Variance', 'Sum Entropy', 'GLCM Entropy',\n",
    "        'Difference Variance', 'Difference Entropy', 'IMC1', 'IMC2', 'MCC'\n",
    "    ]\n",
    "\n",
    "    # ───────────── NEW VISUAL OUTPUT (feature maps) ─────────────\n",
    "    # These maps provide a visual representation of the texture numbers.\n",
    "    MAKE_FEATURE_MAPS = True\n",
    "    SAVE_FEATURE_MAPS = True\n",
    "    FEATURE_MAP_OUTDIR = \"texture_feature_maps\"\n",
    "    WIN  = 32      # window size in pixels (increase for smoother, decrease for finer local detail)\n",
    "    STEP = 8       # stride in pixels (smaller = denser map but slower)\n",
    "    GLCM_LEVELS = 32  # quantization levels for faster/stable GLCM (16/32/64 recommended)\n",
    "    OFFSETS = [(1,0), (1,-1), (0,-1), (-1,-1)]  # 0°,45°,90°,135° at distance=1\n",
    "    FEATURES_TO_MAP = ['Contrast', 'Homogeneity', 'GLCM Entropy', 'Entropy']  # edit as needed\n",
    "\n",
    "    # If you still want the summary charts (heatmap table / radar), set this True.\n",
    "    SHOW_SUMMARY_CHARTS = False\n",
    "\n",
    "\n",
    "    all_features = []\n",
    "    grays = []\n",
    "    glcm_avgs = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        print(f\"\\nProcessing image: {path}\")\n",
    "        gray, glcm_avg, features = analyze_image(path)\n",
    "        grays.append(gray)\n",
    "        glcm_avgs.append(glcm_avg)\n",
    "        all_features.append(features)\n",
    "\n",
    "        # Print features for this image\n",
    "        print(\"Texture Features:\")\n",
    "        for name, val in zip(feature_names, features):\n",
    "            print(f\"{name}: {val:.4f}\")\n",
    "\n",
    "    \n",
    "    # ───────────── NEW: Per-image FEATURE MAPS (heatmaps + overlays) ─────────────\n",
    "    if MAKE_FEATURE_MAPS:\n",
    "        out_dir = FEATURE_MAP_OUTDIR\n",
    "        if SAVE_FEATURE_MAPS:\n",
    "            ensure_dir(out_dir)\n",
    "\n",
    "        for gray_u8, path in zip(grays, image_paths):\n",
    "            img_name = os.path.splitext(os.path.basename(path))[0]\n",
    "            fmap_dict, meta = texture_feature_maps(\n",
    "                gray_img_u8=gray_u8,\n",
    "                win=WIN,\n",
    "                step=STEP,\n",
    "                levels=GLCM_LEVELS,\n",
    "                offsets=OFFSETS,\n",
    "                features_to_map=FEATURES_TO_MAP\n",
    "            )\n",
    "            save_dir = out_dir if SAVE_FEATURE_MAPS else None\n",
    "            plot_feature_maps(\n",
    "                gray_img_u8=gray_u8,\n",
    "                fmap_dict=fmap_dict,\n",
    "                meta=meta,\n",
    "                image_title=img_name,\n",
    "                overlay_alpha=0.45,\n",
    "                save_dir=save_dir,\n",
    "                dpi=300\n",
    "            )\n",
    "\n",
    "# Individual plots for each image\n",
    "    for i, (gray, glcm_avg, path) in enumerate(zip(grays, glcm_avgs, image_paths)):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        axs[0].imshow(gray, cmap='gray')\n",
    "        axs[0].set_title(f'Grayscale: {path.split(\"/\")[-1]}')\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        flat = gray.flatten()\n",
    "        axs[1].hist(flat, bins=256, density=True, color='blue')\n",
    "        axs[1].set_title('Intensity Histogram')\n",
    "\n",
    "        axs[2].imshow(glcm_avg, cmap='jet')\n",
    "        axs[2].set_title('Average GLCM')\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    # (Summary charts removed; feature maps are the primary output.)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887adf0",
   "metadata": {},
   "source": [
    "\n",
    "## Comparative analysis for M0–M3 (fixed filenames; RGBA-safe loader)\n",
    "\n",
    "This section loads **four images** from:\n",
    "\n",
    "`C:\\Users\\User\\Pictures`\n",
    "\n",
    "with basenames **M0, M1, M2, M3** (any of: png/jpg/jpeg/tif/tiff/bmp).\n",
    "\n",
    "It produces:\n",
    "- Global feature comparisons (bar plots) across the four images\n",
    "- A normalized radar “fingerprint” plot\n",
    "- Feature-map grids (M0–M3 side-by-side) with **the same color scale**\n",
    "- Overlay grids (feature map overlaid on original)\n",
    "\n",
    "**Fix included:** Handles RGBA images (shape H×W×4) by converting RGBA→RGB→Gray.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# USER SETTINGS\n",
    "# -----------------------------\n",
    "IMG_DIR = r\"C:\\Users\\User\\Pictures\"\n",
    "IMG_NAMES = [\"M0\", \"M1\", \"M2\", \"M3\"]\n",
    "OUT_DIR = os.path.join(IMG_DIR, \"texture_feature_maps_M0_M3\")\n",
    "\n",
    "WIN = 32\n",
    "STEP = 8\n",
    "\n",
    "FEATURE_MAPS_TO_PLOT = [\"Contrast\", \"Homogeneity\", \"GLCM Entropy\", \"Entropy\"]\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def find_image_path(img_dir, basename):\n",
    "    exts = [\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"]\n",
    "    for ext in exts:\n",
    "        p = os.path.join(img_dir, basename + ext)\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    for fn in os.listdir(img_dir):\n",
    "        if fn.lower().startswith(basename.lower() + \".\"):\n",
    "            return os.path.join(img_dir, fn)\n",
    "    raise FileNotFoundError(f\"Could not find image for {basename} in {img_dir}\")\n",
    "\n",
    "\n",
    "def _ensure_float01(img):\n",
    "    img = np.asarray(img)\n",
    "    if img.dtype != np.float32 and img.dtype != np.float64:\n",
    "        img = img.astype(np.float32)\n",
    "    mn, mx = float(np.min(img)), float(np.max(img))\n",
    "    if mx - mn < 1e-12:\n",
    "        return np.zeros_like(img, dtype=np.float32)\n",
    "    if mx > 1.5:\n",
    "        img = (img - mn) / (mx - mn + 1e-12)\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "\n",
    "def load_image_for_texture(path):\n",
    "    # Try to reuse earlier function if present\n",
    "    if \"load_grayscale\" in globals():\n",
    "        return _ensure_float01(load_grayscale(path))\n",
    "    if \"load_and_preprocess_image\" in globals():\n",
    "        return _ensure_float01(load_and_preprocess_image(path))\n",
    "\n",
    "    # RGBA-safe loader\n",
    "    from skimage import io, color\n",
    "    im = io.imread(path)\n",
    "\n",
    "    # RGBA -> RGB\n",
    "    if im.ndim == 3 and im.shape[2] == 4:\n",
    "        im = color.rgba2rgb(im)\n",
    "\n",
    "    # RGB -> Gray\n",
    "    if im.ndim == 3 and im.shape[2] == 3:\n",
    "        im = color.rgb2gray(im)\n",
    "\n",
    "    return _ensure_float01(im)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Feature extractors\n",
    "# -----------------------------\n",
    "def extract_global_features(img_float01):\n",
    "    # Prefer your existing extractor if present\n",
    "    if \"extract_texture_features\" in globals():\n",
    "        return extract_texture_features(img_float01)\n",
    "    if \"compute_texture_features\" in globals():\n",
    "        return compute_texture_features(img_float01)\n",
    "\n",
    "    # Fallback minimal global set\n",
    "    from skimage.feature import graycomatrix, graycoprops\n",
    "    from skimage.util import img_as_ubyte\n",
    "\n",
    "    img_u8 = img_as_ubyte(img_float01)\n",
    "    levels = 32\n",
    "    q = (img_u8.astype(np.float32) / 255.0 * (levels - 1)).astype(np.uint8)\n",
    "\n",
    "    glcm = graycomatrix(\n",
    "        q,\n",
    "        distances=[1, 2, 3],\n",
    "        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "        levels=levels,\n",
    "        symmetric=True,\n",
    "        normed=True,\n",
    "    )\n",
    "\n",
    "    feats = {\n",
    "        \"Contrast\": float(np.mean(graycoprops(glcm, \"contrast\"))),\n",
    "        \"Homogeneity\": float(np.mean(graycoprops(glcm, \"homogeneity\"))),\n",
    "        \"Energy\": float(np.mean(graycoprops(glcm, \"energy\"))),\n",
    "        \"Correlation\": float(np.mean(graycoprops(glcm, \"correlation\"))),\n",
    "        \"ASM\": float(np.mean(graycoprops(glcm, \"ASM\"))),\n",
    "    }\n",
    "\n",
    "    # First-order entropy\n",
    "    hist, _ = np.histogram(img_float01, bins=64, range=(0, 1), density=True)\n",
    "    hist = hist + 1e-12\n",
    "    feats[\"Entropy\"] = float(-np.sum(hist * np.log2(hist)))\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def compute_feature_maps_for_image(img_float01, win=WIN, step=STEP):\n",
    "    # Prefer your existing local-map function if present\n",
    "    if \"sliding_window_feature_maps\" in globals():\n",
    "        maps, grid = sliding_window_feature_maps(img_float01, win=win, step=step)\n",
    "        # normalize keys to Title case if needed\n",
    "        return maps, grid\n",
    "    if \"compute_feature_maps\" in globals():\n",
    "        maps, grid = compute_feature_maps(img_float01, win=win, step=step)\n",
    "        return maps, grid\n",
    "\n",
    "    # Fallback: patch-wise GLCM + entropy maps\n",
    "    from skimage.feature import graycomatrix, graycoprops\n",
    "    from skimage.util import img_as_ubyte\n",
    "\n",
    "    img_u8 = img_as_ubyte(img_float01)\n",
    "    H, W = img_u8.shape\n",
    "    ys = list(range(0, H - win + 1, step))\n",
    "    xs = list(range(0, W - win + 1, step))\n",
    "\n",
    "    levels = 32\n",
    "    distances = [1, 2, 3]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "    maps = {k: np.zeros((len(ys), len(xs)), dtype=np.float32) for k in\n",
    "            [\"Contrast\", \"Homogeneity\", \"Energy\", \"Correlation\", \"ASM\", \"GLCM Entropy\", \"Entropy\"]}\n",
    "\n",
    "    for i, y in enumerate(ys):\n",
    "        for j, x in enumerate(xs):\n",
    "            patch = img_u8[y:y+win, x:x+win]\n",
    "            q = (patch.astype(np.float32) / 255.0 * (levels - 1)).astype(np.uint8)\n",
    "            glcm = graycomatrix(q, distances=distances, angles=angles,\n",
    "                                levels=levels, symmetric=True, normed=True)\n",
    "\n",
    "            maps[\"Contrast\"][i, j] = float(np.mean(graycoprops(glcm, \"contrast\")))\n",
    "            maps[\"Homogeneity\"][i, j] = float(np.mean(graycoprops(glcm, \"homogeneity\")))\n",
    "            maps[\"Energy\"][i, j] = float(np.mean(graycoprops(glcm, \"energy\")))\n",
    "            maps[\"Correlation\"][i, j] = float(np.mean(graycoprops(glcm, \"correlation\")))\n",
    "            maps[\"ASM\"][i, j] = float(np.mean(graycoprops(glcm, \"ASM\")))\n",
    "\n",
    "            # GLCM entropy: -sum(P log2 P)\n",
    "            P = glcm.astype(np.float32)\n",
    "            P = P / (np.sum(P, axis=(0, 1), keepdims=True) + 1e-12)\n",
    "            glcm_ent = -np.sum(P * np.log2(P + 1e-12), axis=(0, 1))\n",
    "            maps[\"GLCM Entropy\"][i, j] = float(np.mean(glcm_ent))\n",
    "\n",
    "            # First-order entropy on patch\n",
    "            p = patch.astype(np.float32)\n",
    "            p = (p - p.min()) / (p.max() - p.min() + 1e-12)\n",
    "            hist, _ = np.histogram(p, bins=64, range=(0, 1), density=True)\n",
    "            hist = hist + 1e-12\n",
    "            maps[\"Entropy\"][i, j] = float(-np.sum(hist * np.log2(hist)))\n",
    "\n",
    "    return maps, (ys, xs)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load images + global table\n",
    "# -----------------------------\n",
    "images = {}\n",
    "global_feats = []\n",
    "\n",
    "for name in IMG_NAMES:\n",
    "    p = find_image_path(IMG_DIR, name)\n",
    "    img = load_image_for_texture(p)\n",
    "    images[name] = {\"path\": p, \"img\": img}\n",
    "    feats = extract_global_features(img)\n",
    "    feats[\"Image\"] = name\n",
    "    global_feats.append(feats)\n",
    "\n",
    "df_global = pd.DataFrame(global_feats).set_index(\"Image\")\n",
    "display(df_global)\n",
    "\n",
    "csv_path = os.path.join(OUT_DIR, \"global_texture_features_M0_M3.csv\")\n",
    "df_global.to_csv(csv_path)\n",
    "print(\"Saved:\", csv_path)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Comparative plots (global numbers)\n",
    "# -----------------------------\n",
    "for feat in df_global.columns.tolist():\n",
    "    plt.figure(figsize=(6, 3.5))\n",
    "    plt.bar(df_global.index.tolist(), df_global[feat].values)\n",
    "    plt.title(f\"Global texture feature: {feat}\")\n",
    "    plt.xlabel(\"Image\")\n",
    "    plt.ylabel(feat)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"Global_{feat}_bar.png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Radar fingerprint (normalized 0..1 per feature)\n",
    "dfN = (df_global - df_global.min(axis=0)) / (df_global.max(axis=0) - df_global.min(axis=0) + 1e-12)\n",
    "radar_feats = dfN.columns.tolist()\n",
    "theta = np.linspace(0, 2*np.pi, len(radar_feats), endpoint=False).tolist()\n",
    "theta += theta[:1]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "for img_name in dfN.index:\n",
    "    vals = dfN.loc[img_name, radar_feats].values.tolist()\n",
    "    vals += vals[:1]\n",
    "    ax.plot(theta, vals, linewidth=2, label=img_name)\n",
    "ax.set_thetagrids(np.degrees(theta[:-1]), radar_feats)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(\"Texture feature fingerprint (normalized 0–1)\")\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.35, 1.15))\n",
    "plt.tight_layout()\n",
    "out_radar = os.path.join(OUT_DIR, \"Global_Feature_Fingerprint_Radar.png\")\n",
    "plt.savefig(out_radar, dpi=300)\n",
    "plt.show()\n",
    "print(\"Saved:\", out_radar)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Comparative feature-map grids (visual maps)\n",
    "# -----------------------------\n",
    "for feat_name in FEATURE_MAPS_TO_PLOT:\n",
    "    maps_all = {}\n",
    "    grid_ref = None\n",
    "    for img_name in IMG_NAMES:\n",
    "        img = images[img_name][\"img\"]\n",
    "        fmap_dict, grid = compute_feature_maps_for_image(img, win=WIN, step=STEP)\n",
    "        grid_ref = grid_ref or grid\n",
    "        if feat_name not in fmap_dict:\n",
    "            raise KeyError(f\"Feature map '{feat_name}' not found. Available: {list(fmap_dict.keys())}\")\n",
    "        maps_all[img_name] = fmap_dict[feat_name]\n",
    "\n",
    "    # same color scale across images\n",
    "    all_vals = np.concatenate([maps_all[k].ravel() for k in IMG_NAMES])\n",
    "    vmin, vmax = float(np.nanmin(all_vals)), float(np.nanmax(all_vals))\n",
    "    if vmax - vmin < 1e-12:\n",
    "        vmin, vmax = 0.0, 1.0\n",
    "\n",
    "    # Map grid\n",
    "    plt.figure(figsize=(12, 3.2))\n",
    "    for i, img_name in enumerate(IMG_NAMES, start=1):\n",
    "        plt.subplot(1, 4, i)\n",
    "        plt.imshow(maps_all[img_name], cmap=\"jet\", vmin=vmin, vmax=vmax, interpolation=\"nearest\")\n",
    "        plt.title(img_name)\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(f\"{feat_name} feature maps (same color scale across M0–M3)\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "    out_png = os.path.join(OUT_DIR, f\"MapGrid_{feat_name.replace(' ', '_')}_M0_M3.png\")\n",
    "    plt.savefig(out_png, dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", out_png)\n",
    "\n",
    "    # Overlay grid\n",
    "    ys, xs = grid_ref\n",
    "    plt.figure(figsize=(12, 3.2))\n",
    "    for i, img_name in enumerate(IMG_NAMES, start=1):\n",
    "        img = images[img_name][\"img\"]\n",
    "        fmap = maps_all[img_name]\n",
    "        covered_w = xs[-1] + WIN\n",
    "        covered_h = ys[-1] + WIN\n",
    "\n",
    "        plt.subplot(1, 4, i)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.imshow(fmap, cmap=\"jet\", alpha=0.45, vmin=vmin, vmax=vmax,\n",
    "                   extent=[0, covered_w, covered_h, 0], interpolation=\"nearest\")\n",
    "        plt.title(img_name)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"{feat_name} overlays (same color scale across M0–M3)\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.92])\n",
    "    out_png = os.path.join(OUT_DIR, f\"OverlayGrid_{feat_name.replace(' ', '_')}_M0_M3.png\")\n",
    "    plt.savefig(out_png, dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved:\", out_png)\n",
    "\n",
    "print(\"All outputs saved to:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c23e69",
   "metadata": {},
   "source": [
    "\n",
    "## Manuscript-ready figures (Mayo M0–M3)\n",
    "\n",
    "This section generates the manuscript figures described in the discussion:\n",
    "\n",
    "**Figure 1 (core):**  \n",
    "(A) Originals (M0–M3)  \n",
    "(B) Entropy maps (shared color scale)  \n",
    "(C) GLCM Contrast maps (shared color scale)  \n",
    "(D) Global feature trends vs Mayo score (0–3) + Spearman correlation (if SciPy available)\n",
    "\n",
    "**Figure 2 (optional):**  \n",
    "(A) Normalized feature fingerprint radar (M0–M3)  \n",
    "(B) Global feature bar plots (saved; already generated above)\n",
    "\n",
    "All figures are saved (PNG + PDF) into:\n",
    "`OUT_DIR/manuscript_figures/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a786b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "REGENERATE_FIGURES = True   # set False once figures are final\n",
    "\n",
    "# -----------------------------\n",
    "# Assumptions: previous section already created:\n",
    "#   IMG_NAMES, images (dict), df_global (DataFrame), OUT_DIR, WIN, STEP\n",
    "# -----------------------------\n",
    "\n",
    "FIG_DIR = os.path.join(OUT_DIR, \"manuscript_figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "# Mayo score mapping (ordered)\n",
    "mayo_scores = { \"M0\": 0, \"M1\": 1, \"M2\": 2, \"M3\": 3 }\n",
    "order = [n for n in IMG_NAMES if n in mayo_scores]\n",
    "x = np.array([mayo_scores[n] for n in order], dtype=float)\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: compute feature maps for a specific feature across all images\n",
    "# (uses the same feature-map generator already in the notebook)\n",
    "# -----------------------------\n",
    "def get_maps_for_feature(feat_name):\n",
    "    maps = {}\n",
    "    grid_ref = None\n",
    "    for img_name in order:\n",
    "        img = images[img_name][\"img\"]\n",
    "        fmap_dict, grid = compute_feature_maps_for_image(img, win=WIN, step=STEP)\n",
    "        grid_ref = grid_ref or grid\n",
    "        if feat_name not in fmap_dict:\n",
    "            raise KeyError(f\"Feature map '{feat_name}' not found. Available keys: {list(fmap_dict.keys())}\")\n",
    "        maps[img_name] = fmap_dict[feat_name]\n",
    "    return maps, grid_ref\n",
    "\n",
    "def global_minmax(maps_dict):\n",
    "    all_vals = np.concatenate([maps_dict[k].ravel() for k in order])\n",
    "    vmin, vmax = float(np.nanmin(all_vals)), float(np.nanmax(all_vals))\n",
    "    if vmax - vmin < 1e-12:\n",
    "        vmin, vmax = 0.0, 1.0\n",
    "    return vmin, vmax\n",
    "\n",
    "# -----------------------------\n",
    "# FIGURE 1: Multi-row 4-column panel\n",
    "# Rows: (A) Originals, (B) Entropy map, (C) Contrast map, (D) Global trends\n",
    "# -----------------------------\n",
    "# Choose which spatial features to show (as recommended)\n",
    "MAP_ROW1 = \"Entropy\"\n",
    "MAP_ROW2 = \"Contrast\"  # GLCM contrast map\n",
    "\n",
    "entropy_maps, grid_ref = get_maps_for_feature(MAP_ROW1)\n",
    "contrast_maps, _ = get_maps_for_feature(MAP_ROW2)\n",
    "\n",
    "vminE, vmaxE = global_minmax(entropy_maps)\n",
    "vminC, vmaxC = global_minmax(contrast_maps)\n",
    "\n",
    "# Create figure: 4 columns x 3 rows, with bottom row reserved for trends across full width\n",
    "fig = plt.figure(figsize=(12.5, 9.0))\n",
    "\n",
    "# Row A: Originals\n",
    "for j, img_name in enumerate(order):\n",
    "    ax = plt.subplot2grid((4, 4), (0, j))\n",
    "    ax.imshow(images[img_name][\"img\"], cmap=\"gray\")\n",
    "    ax.set_title(img_name)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Row B: Entropy maps (shared scale)\n",
    "for j, img_name in enumerate(order):\n",
    "    ax = plt.subplot2grid((4, 4), (1, j))\n",
    "    imE = ax.imshow(entropy_maps[img_name], vmin=vminE, vmax=vmaxE, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Entropy map\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Add a colorbar for entropy row (right side)\n",
    "caxE = plt.axes([0.92, 0.62, 0.015, 0.18])  # [left, bottom, width, height] in figure fraction\n",
    "cbE = plt.colorbar(imE, cax=caxE)\n",
    "cbE.set_label(\"Entropy (a.u.)\")\n",
    "\n",
    "# Row C: Contrast maps (shared scale)\n",
    "for j, img_name in enumerate(order):\n",
    "    ax = plt.subplot2grid((4, 4), (2, j))\n",
    "    imC = ax.imshow(contrast_maps[img_name], vmin=vminC, vmax=vmaxC, interpolation=\"nearest\")\n",
    "    ax.set_title(\"GLCM Contrast map\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "caxC = plt.axes([0.92, 0.38, 0.015, 0.18])\n",
    "cbC = plt.colorbar(imC, cax=caxC)\n",
    "cbC.set_label(\"Contrast (a.u.)\")\n",
    "\n",
    "# Row D: Global trends across full width (spans 4 columns)\n",
    "axD = plt.subplot2grid((4, 4), (3, 0), colspan=4)\n",
    "\n",
    "# Pick a compact, interpretable set of global features (use whatever exists in df_global)\n",
    "trend_features = []\n",
    "for cand in [\"Entropy\", \"Contrast\", \"Homogeneity\", \"Energy\", \"ASM\"]:\n",
    "    if cand in df_global.columns:\n",
    "        trend_features.append(cand)\n",
    "\n",
    "# Plot features vs Mayo score (0–3)\n",
    "for feat in trend_features:\n",
    "    y = np.array([df_global.loc[n, feat] for n in order], dtype=float)\n",
    "    axD.plot(x, y, marker=\"o\", linewidth=2, label=feat)\n",
    "\n",
    "axD.set_xticks([0, 1, 2, 3])\n",
    "axD.set_xticklabels([\"M0\", \"M1\", \"M2\", \"M3\"])\n",
    "axD.set_xlabel(\"Mayo Endoscopic Score (ordinal)\")\n",
    "axD.set_ylabel(\"Global texture feature (a.u.)\")\n",
    "axD.set_title(\"Global texture feature trends across Mayo scores\")\n",
    "axD.grid(True, alpha=0.3)\n",
    "axD.legend(ncol=min(3, len(trend_features)), frameon=False)\n",
    "\n",
    "# Optional: Spearman correlations (if scipy available)\n",
    "try:\n",
    "    from scipy.stats import spearmanr\n",
    "    lines = []\n",
    "    for feat in trend_features:\n",
    "        y = np.array([df_global.loc[n, feat] for n in order], dtype=float)\n",
    "        r, p = spearmanr(x, y)\n",
    "        lines.append(f\"{feat}: ρ={r:.2f}, p={p:.3g}\")\n",
    "    txt = \"Spearman (Mayo vs feature): \" + \" | \".join(lines)\n",
    "    axD.text(0.01, -0.28, txt, transform=axD.transAxes, fontsize=9, va=\"top\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Panel labels\n",
    "fig.text(0.02, 0.96, \"(A)\", fontsize=14, fontweight=\"bold\")\n",
    "fig.text(0.02, 0.73, \"(B)\", fontsize=14, fontweight=\"bold\")\n",
    "fig.text(0.02, 0.49, \"(C)\", fontsize=14, fontweight=\"bold\")\n",
    "fig.text(0.02, 0.25, \"(D)\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout(rect=[0.02, 0.03, 0.90, 0.98])\n",
    "\n",
    "fig1_png = os.path.join(FIG_DIR, \"Fig1_Mayo_TextureProgression.png\")\n",
    "fig1_pdf = os.path.join(FIG_DIR, \"Fig1_Mayo_TextureProgression.pdf\")\n",
    "plt.savefig(fig1_png, dpi=600)\n",
    "plt.savefig(fig1_pdf)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved Figure 1:\", fig1_png)\n",
    "print(\"Saved Figure 1:\", fig1_pdf)\n",
    "\n",
    "# -----------------------------\n",
    "# FIGURE 2A: Normalized feature fingerprint radar (cleaned, manuscript-ready)\n",
    "# -----------------------------\n",
    "# Normalize per feature to [0, 1] for fair comparison\n",
    "dfN = (df_global - df_global.min(axis=0)) / (df_global.max(axis=0) - df_global.min(axis=0) + 1e-12)\n",
    "\n",
    "# Choose up to 6 features to keep radar readable\n",
    "radar_candidates = [\"Entropy\", \"Contrast\", \"Homogeneity\", \"Energy\", \"ASM\", \"Correlation\"]\n",
    "radar_feats = [c for c in radar_candidates if c in dfN.columns][:6]\n",
    "if len(radar_feats) >= 3:\n",
    "    theta = np.linspace(0, 2*np.pi, len(radar_feats), endpoint=False).tolist()\n",
    "    theta += theta[:1]\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    for img_name in order:\n",
    "        vals = dfN.loc[img_name, radar_feats].values.tolist()\n",
    "        vals += vals[:1]\n",
    "        ax.plot(theta, vals, linewidth=2, label=img_name)\n",
    "    ax.set_thetagrids(np.degrees(theta[:-1]), radar_feats)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(\"Normalized texture-feature fingerprint (M0–M3)\")\n",
    "    ax.legend(loc=\"upper right\", bbox_to_anchor=(1.25, 1.15), frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig2_png = os.path.join(FIG_DIR, \"Fig2A_TextureFingerprint_Radar.png\")\n",
    "    fig2_pdf = os.path.join(FIG_DIR, \"Fig2A_TextureFingerprint_Radar.pdf\")\n",
    "    plt.savefig(fig2_png, dpi=600)\n",
    "    plt.savefig(fig2_pdf)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Saved Figure 2A:\", fig2_png)\n",
    "    print(\"Saved Figure 2A:\", fig2_pdf)\n",
    "else:\n",
    "    print(\"Radar plot skipped: need >=3 features available in df_global. Found:\", radar_feats)\n",
    "\n",
    "print(\"All manuscript figures saved to:\", FIG_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Med_SAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
